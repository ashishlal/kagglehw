{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import *\n",
    "from skimage.util import montage\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take a curriculum approach to training here. I first expose the model to as many different images of whales as quickly as possible (no oversampling) and train on images resized to 224x224.\n",
    "\n",
    "I would like the conv layers to start picking up on features useful for identifying whales. For that, I want to show the model as rich of a dataset as possible.\n",
    "\n",
    "I then train on images resized to 448x448.\n",
    "\n",
    "Finally, I train on oversampled data. Here, the model will see some images more often than others but I am hoping that this will help alleviate the class imbalance in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastprogress import force_console_behavior\n",
    "import fastprogress\n",
    "fastprogress.fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = force_console_behavior()\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "val_fns = {'69823499d.jpg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}\n",
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'res50-full-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "SZ = 384\n",
    "BS = 64\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.41 s, sys: 798 ms, total: 3.21 s\n",
      "Wall time: 3.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         7.501500    0.273467    \n",
      "2         6.671245    0.180389    \n",
      "3         6.094555    0.012937    \n",
      "4         5.126923    0.341942    \n",
      "5         4.270926    0.039900    \n",
      "6         3.461939    1.203884    \n",
      "7         2.553479    0.000077    \n",
      "8         1.863998    0.000075    \n",
      "9         1.227336    0.000357    \n",
      "10        0.695952    0.000714    \n",
      "11        0.383916    0.000061    \n",
      "12        0.207382    0.000008    \n",
      "13        0.143048    0.000001    \n",
      "14        0.107567    0.000003    \n",
      "Total time: 17:26\n",
      "epoch     train_loss  valid_loss\n",
      "1         0.106527    0.000008    \n",
      "2         0.106264    0.000010    \n",
      "3         0.164136    0.000028    \n",
      "4         0.223849    0.002716    \n",
      "5         0.270537    0.000025    \n",
      "6         0.314849    0.003295    \n",
      "7         0.333403    0.000002    \n",
      "8         0.285706    0.000000    \n",
      "9         0.296146    0.000027    \n",
      "10        0.234786    0.000124    \n",
      "11        0.197633    0.000048    \n",
      "12        0.189064    0.000027    \n",
      "13        0.158066    0.000002    \n",
      "14        0.133036    0.000040    \n",
      "15        0.120734    0.000000    \n",
      "16        0.086940    0.000004    \n",
      "17        0.078825    0.000010    \n",
      "18        0.065385    0.000162    \n",
      "19        0.044053    0.000053    \n",
      "20        0.043441    0.000004    \n",
      "21        0.038484    0.000008    \n",
      "22        0.040590    0.000011    \n",
      "23        0.028436    0.000015    \n",
      "24        0.029300    0.000017    \n",
      "Total time: 38:33\n",
      "CPU times: user 38min 43s, sys: 14min 37s, total: 53min 21s\n",
      "Wall time: 56min 2s\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(14, 1e-2)\n",
    "learn.save(f'{name}-stage-1')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(24, lrs)\n",
    "learn.save(f'{name}-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224 * 2\n",
    "BS = 64 // 4\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         0.518923    0.000000    \n",
      "2         0.518838    0.000000    \n",
      "3         0.577872    0.000002    \n",
      "4         0.606787    0.000000    \n",
      "5         0.684259    0.000000    \n",
      "6         0.748076    0.000002    \n",
      "7         0.717744    0.000000    \n",
      "8         0.718881    0.000000    \n",
      "9         0.735095    0.000002    \n",
      "10        0.699363    0.000004    \n",
      "11        0.664675    0.000001    \n",
      "12        0.690950    0.000017    \n",
      "13        0.563404    0.000004    \n",
      "14        0.574512    0.000004    \n",
      "15        0.510566    0.000038    \n",
      "16        0.554237    0.000002    \n",
      "17        0.498543    0.000002    \n",
      "18        0.449977    0.000000    \n",
      "19        0.420661    0.000002    \n",
      "20        0.369140    0.000004    \n",
      "21        0.397967    0.000002    \n",
      "22        0.372123    0.000004    \n",
      "Total time: 2:14:41\n",
      "CPU times: user 1h 36min 10s, sys: 37min 51s, total: 2h 14min 2s\n",
      "Wall time: 2h 14min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "# learn.load(f'{name}-stage-2')\n",
    "learn.load(f'{name}-stage-3')\n",
    "# learn.freeze_to(-1)\n",
    "\n",
    "# learn.fit_one_cycle(12, 1e-2 / 4)\n",
    "# learn.save(f'{name}-stage-3')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(22, lrs)\n",
    "learn.save(f'{name}-stage-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with oversampling\n",
    "df = pd.read_csv('../data/oversampled_train_and_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df, '../data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         1.765668    0.000024    \n",
      "2         0.624019    0.000000    \n",
      "Total time: 42:09\n",
      "epoch     train_loss  valid_loss\n",
      "1         0.701914    0.000000    \n",
      "2         0.672839    0.000021    \n",
      "3         0.579063    0.000016    \n",
      "Total time: 1:27:37\n",
      "CPU times: user 1h 33min 6s, sys: 36min 28s, total: 2h 9min 34s\n",
      "Wall time: 2h 9min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-4')\n",
    "learn.freeze_to(-1)\n",
    "\n",
    "learn.fit_one_cycle(2, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-5')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(3, lrs)\n",
    "learn.save(f'{name}-stage-6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat((preds, torch.ones_like(preds[:, :1])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:, 5004] = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = learn.data.classes + ['new_whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targs = torch.tensor([classes.index(label.obj) if label else 5004 for label in learn.data.valid_ds.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map5fast(preds, targs, k=10):\n",
    "    predicted_idxs = preds.sort(descending=True)[1]\n",
    "    top_5 = predicted_idxs[:, :5]\n",
    "    scores = torch.zeros(len(preds), k).float()\n",
    "    for kk in range(k):\n",
    "        scores[:,kk] = (top_5[:,kk] == targs).float() / float((kk+1))\n",
    "    return scores.max(dim=1)[0].mean()\n",
    "\n",
    "def map55(preds,targs):\n",
    "    if type(preds) is list:\n",
    "        return torch.cat([map5fast(p, targs, 5).view(1) for p in preds ]).mean()\n",
    "    return map5fast(preds,targs, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb73c8282dcc42568de3bbf6b2d56089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 7min 44s, sys: 28.4 s, total: 8min 12s\n",
      "Wall time: 7min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm_notebook\n",
    "res = []\n",
    "ps = np.linspace(0, 1, 101)\n",
    "for p in tqdm_notebook(ps):\n",
    "    preds[:, 5004] = p\n",
    "    res.append(map55(preds, targs).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00759631535038352,\n",
       " 0.006987018510699272,\n",
       " 0.005956868175417185,\n",
       " 0.005766331683844328,\n",
       " 0.0056574540212750435,\n",
       " 0.005573702044785023,\n",
       " 0.005510888062417507,\n",
       " 0.005462730303406715,\n",
       " 0.0053999163210392,\n",
       " 0.0053999163210392,\n",
       " 0.005337102338671684,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.005211473908275366,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.00514865992590785,\n",
       " 0.005023031961172819,\n",
       " 0.005023031961172819,\n",
       " 0.005023031961172819,\n",
       " 0.005023031961172819,\n",
       " 0.00452051917091012]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0045)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without predicting new_whale\n",
    "map55(preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_p = ps[np.argmax(res)]; best_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(preds, learn.data, name, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41d6736e1.jpg</td>\n",
       "      <td>w_7e56d66 new_whale w_2ac6611 w_700ebb4 w_bca4304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c68904c64.jpg</td>\n",
       "      <td>new_whale w_a92e68e w_4a8a4c9 w_abd456f w_b9edd7b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361293a53.jpg</td>\n",
       "      <td>new_whale w_171ca39 w_150a6f5 w_bf5403e w_d0e6e7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0a9b3c0dc.jpg</td>\n",
       "      <td>w_0abdaf4 new_whale w_5babd8c w_40a6c9c w_b3ca4b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0f41d9dee.jpg</td>\n",
       "      <td>new_whale w_5482351 w_ad88c85 w_0e0f074 w_3ff114c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image                                                 Id\n",
       "0  41d6736e1.jpg  w_7e56d66 new_whale w_2ac6611 w_700ebb4 w_bca4304\n",
       "1  c68904c64.jpg  new_whale w_a92e68e w_4a8a4c9 w_abd456f w_b9edd7b\n",
       "2  361293a53.jpg  new_whale w_171ca39 w_150a6f5 w_bf5403e w_d0e6e7d\n",
       "3  0a9b3c0dc.jpg  w_0abdaf4 new_whale w_5babd8c w_40a6c9c w_b3ca4b7\n",
       "4  0f41d9dee.jpg  new_whale w_5482351 w_ad88c85 w_0e0f074 w_3ff114c"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4614321608040201"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').Id.str.split().apply(lambda x: x[0] == 'new_whale').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 184k/184k [00:13<00:00, 13.6kB/s]\n",
      "Successfully submitted to Humpback Whale Identification"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c humpback-whale-identification -f subs/{name}.csv.gz -m \"{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName                 date                 description       status    publicScore  privateScore  \r\n",
      "-----------------------  -------------------  ----------------  --------  -----------  ------------  \r\n",
      "res50-full-train.csv.gz  2019-02-20 23:10:32  res50-full-train  complete  0.757        None          \r\n",
      "res50-full-train.csv.gz  2019-02-20 23:08:39  res50-full-train  complete  0.712        None          \r\n",
      "res50-full-train.csv.gz  2019-02-20 23:07:12  res50-full-train  complete  0.649        None          \r\n",
      "res50-full-train.csv.gz  2019-02-20 19:54:45  res50-full-train  complete  0.749        None          \r\n",
      "sub7d.csv                2019-02-20 00:22:56  None              complete  0.866        None          \r\n",
      "sub7c.csv                2019-02-16 21:40:09  None              complete  0.276        None          \r\n",
      "sub7b.csv                2019-02-14 19:57:55  None              complete  0.868        None          \r\n",
      "sub7a.csv                2019-02-14 03:10:42  None              complete  0.857        None          \r\n",
      "sub7a.csv                2019-02-12 00:49:00  None              complete  0.487        None          \r\n",
      "sub7.csv                 2019-02-11 16:29:58  None              complete  0.544        None          \r\n",
      "sub2.csv.gz              2018-12-23 06:51:40                    complete  0.785        None          \r\n",
      "sub1-0.008.csv           2018-12-06 20:15:30                    error     None         None          \r\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions -c humpback-whale-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai1_0",
   "language": "python",
   "name": "fastai1_0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
