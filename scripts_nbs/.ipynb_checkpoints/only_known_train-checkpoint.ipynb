{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import *\n",
    "from skimage.util import montage\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take a curriculum approach to training here. I first expose the model to as many different images of whales as quickly as possible (no oversampling) and train on images resized to 224x224.\n",
    "\n",
    "I would like the conv layers to start picking up on features useful for identifying whales. For that, I want to show the model as rich of a dataset as possible.\n",
    "\n",
    "I then train on images resized to 448x448.\n",
    "\n",
    "Finally, I train on oversampled data. Here, the model will see some images more often than others but I am hoping that this will help alleviate the class imbalance in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastprogress import force_console_behavior\n",
    "import fastprogress\n",
    "fastprogress.fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = force_console_behavior()\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "val_fns = {'69823499d.jpg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}\n",
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'res50-full-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "BS = 64\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.51 s, sys: 844 ms, total: 3.35 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         7.488658    0.212913    \n",
      "2         6.698018    0.009669    \n",
      "3         6.110320    1.649534    \n",
      "4         5.145953    0.010905    \n",
      "5         4.344628    0.622688    \n",
      "6         3.427283    0.001436    \n",
      "7         2.693983    0.006930    \n",
      "8         1.889978    0.000161    \n",
      "9         1.200347    0.000006    \n",
      "10        0.743178    0.000083    \n",
      "11        0.427395    0.000000    \n",
      "12        0.231724    0.000001    \n",
      "13        0.147966    0.000000    \n",
      "14        0.114749    0.000000    \n",
      "Total time: 18:46\n",
      "epoch     train_loss  valid_loss\n",
      "1         0.125161    0.000000    \n",
      "2         0.125646    0.000000    \n",
      "3         0.168645    0.000001    \n",
      "4         0.224942    0.000000    \n",
      "5         0.262029    0.000547    \n",
      "6         0.288204    0.000000    \n",
      "7         0.328155    0.000162    \n",
      "8         0.306801    0.000023    \n",
      "9         0.264029    0.000000    \n",
      "10        0.239775    0.000000    \n",
      "11        0.217391    0.000004    \n",
      "12        0.192243    0.000008    \n",
      "13        0.173145    0.000010    \n",
      "14        0.145627    0.000002    \n",
      "15        0.126741    0.000000    \n",
      "16        0.098531    0.000001    \n",
      "17        0.077079    0.000016    \n",
      "18        0.069661    0.000029    \n",
      "19        0.051832    0.000000    \n",
      "20        0.042017    0.000002    \n",
      "21        0.042970    0.000002    \n",
      "22        0.036259    0.000002    \n",
      "23        0.035793    0.000000    \n",
      "24        0.032346    0.000000    \n",
      "Total time: 38:56\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "learn.fit_one_cycle(14, 1e-2)\n",
    "learn.save(f'{name}-stage-1')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(24, lrs)\n",
    "learn.save(f'{name}-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224 * 2\n",
    "BS = 64 // 4\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         1.488783    0.000001    \n",
      "2         0.781213    0.000000    \n",
      "3         0.712935    0.000000    \n",
      "4         0.963552    0.000004    \n",
      "5         1.219762    0.000000    \n",
      "6         1.474415    0.000000    \n",
      "7         1.792757    0.000019    \n",
      "8         2.021285    0.000000    \n",
      "9         2.130956    0.000000    \n",
      "10        2.228688    0.000001    \n",
      "11        2.331408    0.000000    \n",
      "12        2.517759    0.000000    \n",
      "13        2.376398    0.000000    \n",
      "14        2.373355    0.000000    \n",
      "15        2.386347    0.000000    \n",
      "16        2.220315    0.000000    \n",
      "17        2.051613    0.000001    \n",
      "18        2.181615    0.000008    \n",
      "19        2.061087    0.000000    \n",
      "20        2.035984    0.000008    \n",
      "21        1.833481    0.000001    \n",
      "22        1.702043    0.000001    \n",
      "23        1.536841    0.000002    \n",
      "24        1.463844    0.000001    \n",
      "Total time: 1:48:34\n",
      "epoch     train_loss  valid_loss\n",
      "1         1.598646    0.000001    \n",
      "2         1.517286    0.000001    \n",
      "3         1.530495    0.000000    \n",
      "4         1.514191    0.000000    \n",
      "5         1.674834    0.000007    \n",
      "6         1.780624    0.000017    \n",
      "7         1.871329    0.000004    \n",
      "8         2.047295    0.000006    \n",
      "9         2.267360    0.000004    \n",
      "10        2.191292    0.000008    \n",
      "11        2.324455    0.000103    \n",
      "12        2.351832    0.000011    \n",
      "13        2.487766    0.000004    \n",
      "14        2.529901    0.000031    \n",
      "15        2.635113    0.000002    \n",
      "16        2.526319    0.000008    \n",
      "17        2.636019    0.000001    \n",
      "18        2.780694    0.000017    \n",
      "19        2.798976    0.000000    \n",
      "20        2.796325    0.000004    \n",
      "21        2.646297    0.000034    \n",
      "22        2.797672    0.000013    \n",
      "23        2.725103    0.000002    \n",
      "24        2.841321    0.000000    \n",
      "25        2.719926    0.000005    \n",
      "26        2.718988    24.094868   \n",
      "27        2.695052    0.000010    \n",
      "28        2.633448    0.000021    \n",
      "29        2.763542    0.000002    \n",
      "30        2.836553    0.000021    \n",
      "31        2.768213    0.000000    \n",
      "32        2.697949    0.000069    \n",
      "33        2.616240    0.000004    \n",
      "34        2.577736    0.000036    \n",
      "35        2.674387    0.000065    \n",
      "36        2.687900    0.000019    \n",
      "37        2.752322    0.000038    \n",
      "38        2.554064    0.000004    \n",
      "39        2.638994    0.000019    \n",
      "40        2.528038    0.000023    \n",
      "41        2.535930    0.000015    \n",
      "42        2.393777    0.000057    \n",
      "43        2.494830    0.000011    \n",
      "44        2.491839    0.000042    \n",
      "Total time: 4:35:09\n",
      "CPU times: user 4h 36min 30s, sys: 1h 45min 26s, total: 6h 21min 57s\n",
      "Wall time: 6h 23min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-2')\n",
    "# learn.load(f'{name}-stage-3')\n",
    "learn.freeze_to(-1)\n",
    "\n",
    "learn.fit_one_cycle(24, 1e-2 / 4)\n",
    "# learn.fit_one_cycle(12, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-3')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(44, lrs)\n",
    "# learn.fit_one_cycle(22, lrs)\n",
    "learn.save(f'{name}-stage-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with oversampling\n",
    "df = pd.read_csv('../data/oversampled_train_and_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df, '../data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         2.704631    0.000149    \n",
      "2         2.569817    557.161499  \n",
      "3         2.684457    197.819656  \n",
      "4         2.248218    68.272034   \n",
      "5         1.829801    6.009163    \n",
      "6         1.637777    248.953278  \n",
      "7         1.571471    0.000134    \n",
      "8         1.352860    0.000011    \n",
      "9         1.480265    0.000137    \n",
      "10        1.605890    0.002937    \n",
      "11        1.982956    145.073669  \n",
      "12        2.344408    0.099056    \n",
      "13        2.887636    12.574604   \n",
      "14        3.240505    2.706734    \n",
      "Total time: 5:09:19\n",
      "epoch     train_loss  valid_loss\n",
      "1         3.637343    0.010223    \n",
      "2         3.955417    0.076408    \n",
      "3         3.521924    2.532550    \n",
      "4         2.965347    0.206098    \n",
      "5         2.585325    0.010826    \n",
      "6         2.331424    1.396721    \n",
      "7         2.243938    0.013039    \n",
      "8         2.298476    51.148140   \n",
      "9         2.164433    62.201359   \n",
      "10        2.156010    0.027977    \n",
      "11        2.097930    0.001144    \n",
      "12        2.077401    0.024689    \n",
      "13        2.021029    0.012650    \n",
      "14        2.116576    0.029114    \n",
      "15        2.078630    0.502666    \n",
      "16        2.064131    0.007351    \n",
      "17        2.246198    0.021729    \n",
      "18        2.431100    0.005447    \n",
      "19        2.573259    0.010399    \n",
      "20        2.964917    0.012329    \n",
      "21        3.271386    0.028954    \n",
      "22        3.573627    0.114670    \n",
      "23        3.597869    0.064651    \n",
      "24        3.507641    0.028000    \n",
      "Total time: 12:07:28\n",
      "CPU times: user 12h 29min 30s, sys: 4h 45min 43s, total: 17h 15min 13s\n",
      "Wall time: 17h 16min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-4')\n",
    "learn.freeze_to(-1)\n",
    "\n",
    "# learn.fit_one_cycle(2, 1e-2 / 4)\n",
    "learn.fit_one_cycle(14, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-5')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "# learn.fit_one_cycle(3, lrs)\n",
    "learn.fit_one_cycle(24, lrs)\n",
    "learn.save(f'{name}-stage-6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat((preds, torch.ones_like(preds[:, :1])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:, 5004] = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../cache/preds_resnet50_2', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = learn.data.classes + ['new_whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targs = torch.tensor([classes.index(label.obj) if label else 5004 for label in learn.data.valid_ds.y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map5fast(preds, targs, k=10):\n",
    "    predicted_idxs = preds.sort(descending=True)[1]\n",
    "    top_5 = predicted_idxs[:, :5]\n",
    "    scores = torch.zeros(len(preds), k).float()\n",
    "    for kk in range(k):\n",
    "        scores[:,kk] = (top_5[:,kk] == targs).float() / float((kk+1))\n",
    "    return scores.max(dim=1)[0].mean()\n",
    "\n",
    "def map55(preds,targs):\n",
    "    if type(preds) is list:\n",
    "        return torch.cat([map5fast(p, targs, 5).view(1) for p in preds ]).mean()\n",
    "    return map5fast(preds,targs, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from tqdm import tqdm_notebook\n",
    "# res = []\n",
    "# ps = np.linspace(0, 1, 101)\n",
    "# for p in tqdm_notebook(ps):\n",
    "#     preds[:, 5004] = p\n",
    "#     res.append(map55(preds, targs).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(preds, learn.data, name, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41d6736e1.jpg</td>\n",
       "      <td>new_whale w_7e56d66 w_bca4304 w_71df35a w_af8df07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c68904c64.jpg</td>\n",
       "      <td>w_778e474 w_08630fd new_whale w_3de9056 w_59052ad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361293a53.jpg</td>\n",
       "      <td>new_whale w_c7d8935 w_0027efa w_171ca39 w_e16924b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0a9b3c0dc.jpg</td>\n",
       "      <td>new_whale w_0abdaf4 w_d72771c w_3756834 w_8eae2c3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0f41d9dee.jpg</td>\n",
       "      <td>new_whale w_91cc02c w_efcbb06 w_60ce6fc w_70fc054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image                                                 Id\n",
       "0  41d6736e1.jpg  new_whale w_7e56d66 w_bca4304 w_71df35a w_af8df07\n",
       "1  c68904c64.jpg  w_778e474 w_08630fd new_whale w_3de9056 w_59052ad\n",
       "2  361293a53.jpg  new_whale w_c7d8935 w_0027efa w_171ca39 w_e16924b\n",
       "3  0a9b3c0dc.jpg  new_whale w_0abdaf4 w_d72771c w_3756834 w_8eae2c3\n",
       "4  0f41d9dee.jpg  new_whale w_91cc02c w_efcbb06 w_60ce6fc w_70fc054"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8006281407035176"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').Id.str.split().apply(lambda x: x[0] == 'new_whale').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 176k/176k [00:07<00:00, 23.6kB/s]\n",
      "Successfully submitted to Humpback Whale Identification"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c humpback-whale-identification -f subs/{name}.csv.gz -m \"{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName                  date                 description        status    publicScore  privateScore  \r\n",
      "------------------------  -------------------  -----------------  --------  -----------  ------------  \r\n",
      "res50-full-train.csv.gz   2019-02-25 10:34:52  res50-full-train   complete  0.575        None          \r\n",
      "res50-full-train.csv.gz   2019-02-25 01:55:44  res50-full-train   complete  0.587        None          \r\n",
      "sub7l.csv                 2019-02-23 14:59:37  None               complete  0.890        None          \r\n",
      "sub7k.csv                 2019-02-23 14:58:45  None               complete  0.892        None          \r\n",
      "sub7j.csv                 2019-02-23 14:58:00  None               complete  0.891        None          \r\n",
      "sub7h.csv                 2019-02-22 06:16:45  None               complete  0.890        None          \r\n",
      "sub7h.csv                 2019-02-22 06:13:13  None               complete  0.889        None          \r\n",
      "sub7h.csv                 2019-02-22 06:07:58  None               complete  0.879        None          \r\n",
      "sub11.csv                 2019-02-22 06:00:10  None               complete  0.791        None          \r\n",
      "sub7h.csv                 2019-02-22 05:55:22  None               complete  0.868        None          \r\n",
      "sub7g.csv                 2019-02-21 11:49:23  None               complete  0.835        None          \r\n",
      "sub7f.csv                 2019-02-21 10:00:29  None               complete  0.875        None          \r\n",
      "sub7f.csv                 2019-02-21 09:51:32  None               complete  0.814        None          \r\n",
      "sub7f.csv                 2019-02-21 09:27:07  None               complete  0.794        None          \r\n",
      "den121-full-train.csv.gz  2019-02-21 08:08:02  den121-full-train  complete  0.744        None          \r\n",
      "res50-full-train.csv.gz   2019-02-20 23:10:32  res50-full-train   complete  0.757        None          \r\n",
      "res50-full-train.csv.gz   2019-02-20 23:08:39  res50-full-train   complete  0.712        None          \r\n",
      "res50-full-train.csv.gz   2019-02-20 23:07:12  res50-full-train   complete  0.649        None          \r\n",
      "res50-full-train.csv.gz   2019-02-20 19:54:45  res50-full-train   complete  0.749        None          \r\n",
      "sub7d.csv                 2019-02-20 00:22:56  None               complete  0.866        None          \r\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions -c humpback-whale-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai1_0",
   "language": "python",
   "name": "fastai1_0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
