{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import *\n",
    "from skimage.util import montage\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take a curriculum approach to training here. I first expose the model to as many different images of whales as quickly as possible (no oversampling) and train on images resized to 224x224.\n",
    "\n",
    "I would like the conv layers to start picking up on features useful for identifying whales. For that, I want to show the model as rich of a dataset as possible.\n",
    "\n",
    "I then train on images resized to 448x448.\n",
    "\n",
    "Finally, I train on oversampled data. Here, the model will see some images more often than others but I am hoping that this will help alleviate the class imbalance in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastprogress import force_console_behavior\n",
    "import fastprogress\n",
    "fastprogress.fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = force_console_behavior()\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/train.csv')\n",
    "val_fns = {'69823499d.jpg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}\n",
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'res50-full-train'\n",
    "name = f'den121-full-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "BS = 64\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.3 s, sys: 698 ms, total: 3 s\n",
      "Wall time: 3.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.densenet121, lin_ftrs=[2048])\n",
    "learn.clip_grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         7.552574    4.138718    \n",
      "2         6.715404    0.950479    \n",
      "3         6.050995    0.002508    \n",
      "4         5.139301    1.015872    \n",
      "5         4.226835    0.023248    \n",
      "6         3.324532    0.034236    \n",
      "7         2.560887    0.000233    \n",
      "8         1.738997    0.000066    \n",
      "9         1.112600    0.000001    \n",
      "10        0.671867    0.000003    \n",
      "11        0.382803    0.000005    \n",
      "12        0.203173    0.000002    \n",
      "13        0.144431    0.000000    \n",
      "14        0.100741    0.000000    \n",
      "Total time: 20:17\n",
      "epoch     train_loss  valid_loss\n",
      "1         0.093720    0.000000    \n",
      "2         0.098311    0.000000    \n",
      "3         0.098892    0.000001    \n",
      "4         0.110860    0.000000    \n",
      "5         0.123511    0.000000    \n",
      "6         0.143915    0.000000    \n",
      "7         0.126430    0.000003    \n",
      "8         0.154158    0.000000    \n",
      "9         0.133794    0.000000    \n",
      "10        0.135681    0.000000    \n",
      "11        0.118621    0.000000    \n",
      "12        0.106953    0.000001    \n",
      "13        0.101892    0.000000    \n",
      "14        0.081224    0.000001    \n",
      "15        0.070246    0.000000    \n",
      "16        0.064777    0.000000    \n",
      "17        0.060939    0.000000    \n",
      "18        0.044462    0.000000    \n",
      "19        0.040829    0.000000    \n",
      "20        0.037763    0.000000    \n",
      "21        0.033718    0.000000    \n",
      "22        0.031294    0.000000    \n",
      "23        0.029439    0.000000    \n",
      "24        0.025303    0.000000    \n",
      "Total time: 43:24\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(14, 1e-2)\n",
    "learn.save(f'{name}-stage-1')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(24, lrs)\n",
    "learn.save(f'{name}-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224 * 2\n",
    "BS = 64 // 4\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         1.472018    0.000000    \n",
      "2         0.928063    0.000000    \n",
      "3         1.286815    0.000244    \n",
      "4         1.834080    0.000030    \n",
      "5         1.918766    0.000001    \n",
      "6         1.849328    0.000719    \n",
      "7         1.658498    0.000119    \n",
      "8         1.443799    0.000006    \n",
      "9         1.134555    0.000010    \n",
      "10        0.891679    0.000004    \n",
      "11        0.735060    0.000006    \n",
      "12        0.574668    0.000005    \n",
      "Total time: 1:04:08\n",
      "epoch     train_loss  valid_loss\n",
      "1         0.571490    0.000008    \n",
      "2         0.604931    0.000008    \n",
      "3         0.596035    0.000009    \n",
      "4         0.663896    0.000004    \n",
      "5         0.668168    0.000016    \n",
      "6         0.723208    0.000006    \n",
      "7         0.722136    0.000003    \n",
      "8         0.697669    0.000001    \n",
      "9         0.656108    0.000001    \n",
      "10        0.702317    0.000001    \n",
      "11        0.652714    0.000000    \n",
      "12        0.645954    0.000001    \n",
      "13        0.600806    0.000000    \n",
      "14        0.621588    0.000002    \n",
      "15        0.625146    0.000000    \n",
      "16        0.540571    0.000000    \n",
      "17        0.471850    0.000000    \n",
      "18        0.510192    0.000003    \n",
      "19        0.457890    0.000000    \n",
      "20        0.482314    0.000001    \n",
      "21        0.454484    0.000001    \n",
      "22        0.424101    0.000001    \n",
      "Total time: 2:38:11\n",
      "CPU times: user 2h 49min 20s, sys: 51min 58s, total: 3h 41min 19s\n",
      "Wall time: 3h 42min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = create_cnn(data, models.densenet121, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-2')\n",
    "# learn.load(f'{name}-stage-3')\n",
    "learn.freeze_to(-1)\n",
    "\n",
    "learn.fit_one_cycle(12, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-3')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(22, lrs)\n",
    "learn.save(f'{name}-stage-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with oversampling\n",
    "df = pd.read_csv('../data/oversampled_train_and_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df, '../data/train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../data/test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='../data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         1.862462    0.000002    \n",
      "2         0.703604    0.000084    \n",
      "Total time: 52:13\n",
      "epoch     train_loss  valid_loss\n",
      "1         0.695476    0.000079    \n",
      "2         0.768560    0.000130    \n",
      "3         0.617248    0.000181    \n",
      "Total time: 1:44:41\n",
      "CPU times: user 1h 59min 51s, sys: 36min 49s, total: 2h 36min 40s\n",
      "Wall time: 2h 36min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = create_cnn(data, models.densenet121, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-4')\n",
    "learn.freeze_to(-1)\n",
    "\n",
    "learn.fit_one_cycle(2, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-5')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(3, lrs)\n",
    "learn.save(f'{name}-stage-6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat((preds, torch.ones_like(preds[:, :1])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:, 5004] = 0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = learn.data.classes + ['new_whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(preds, learn.data, name, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41d6736e1.jpg</td>\n",
       "      <td>w_7e56d66 w_e2530bf new_whale w_d2c2be0 w_8b8dca8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c68904c64.jpg</td>\n",
       "      <td>new_whale w_492d9c5 w_2f3badb w_e798363 w_72fea5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>361293a53.jpg</td>\n",
       "      <td>new_whale w_171ca39 w_3132fce w_5f0fcab w_da443d9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0a9b3c0dc.jpg</td>\n",
       "      <td>w_0abdaf4 new_whale w_d7b6f17 w_efa100e w_c928809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0f41d9dee.jpg</td>\n",
       "      <td>new_whale w_9714922 w_6d8f72e w_491b2e5 w_550dd10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image                                                 Id\n",
       "0  41d6736e1.jpg  w_7e56d66 w_e2530bf new_whale w_d2c2be0 w_8b8dca8\n",
       "1  c68904c64.jpg  new_whale w_492d9c5 w_2f3badb w_e798363 w_72fea5e\n",
       "2  361293a53.jpg  new_whale w_171ca39 w_3132fce w_5f0fcab w_da443d9\n",
       "3  0a9b3c0dc.jpg  w_0abdaf4 new_whale w_d7b6f17 w_efa100e w_c928809\n",
       "4  0f41d9dee.jpg  new_whale w_9714922 w_6d8f72e w_491b2e5 w_550dd10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4904522613065327"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').Id.str.split().apply(lambda x: x[0] == 'new_whale').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../cache/preds_dn121', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 184k/184k [00:03<00:00, 51.8kB/s]\n",
      "Successfully submitted to Humpback Whale Identification"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c humpback-whale-identification -f subs/{name}.csv.gz -m \"{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fileName                  date                 description        status    publicScore  privateScore  \r\n",
      "------------------------  -------------------  -----------------  --------  -----------  ------------  \r\n",
      "den121-full-train.csv.gz  2019-02-21 08:08:02  den121-full-train  complete  0.744        None          \r\n",
      "res50-full-train.csv.gz   2019-02-20 23:10:32  res50-full-train   complete  0.757        None          \r\n",
      "res50-full-train.csv.gz   2019-02-20 23:08:39  res50-full-train   complete  0.712        None          \r\n",
      "res50-full-train.csv.gz   2019-02-20 23:07:12  res50-full-train   complete  0.649        None          \r\n",
      "res50-full-train.csv.gz   2019-02-20 19:54:45  res50-full-train   complete  0.749        None          \r\n",
      "sub7d.csv                 2019-02-20 00:22:56  None               complete  0.866        None          \r\n",
      "sub7c.csv                 2019-02-16 21:40:09  None               complete  0.276        None          \r\n",
      "sub7b.csv                 2019-02-14 19:57:55  None               complete  0.868        None          \r\n",
      "sub7a.csv                 2019-02-14 03:10:42  None               complete  0.857        None          \r\n",
      "sub7a.csv                 2019-02-12 00:49:00  None               complete  0.487        None          \r\n",
      "sub7.csv                  2019-02-11 16:29:58  None               complete  0.544        None          \r\n",
      "sub2.csv.gz               2018-12-23 06:51:40                     complete  0.785        None          \r\n",
      "sub1-0.008.csv            2018-12-06 20:15:30                     error     None         None          \r\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submissions -c humpback-whale-identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai1_0",
   "language": "python",
   "name": "fastai1_0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
